/home/jovyan/repo/ximeng_project/split0.2_pytorch_ResNet50_nparray.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  inputs = torch.tensor(inputs, dtype=torch.float32)
/home/jovyan/repo/ximeng_project/split0.2_pytorch_ResNet50_nparray.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  inputs = torch.tensor(inputs, dtype=torch.float32)
Sequential(
  (0): Conv2d(5, 3, kernel_size=(3, 3), stride=(3, 3), bias=False)
  (1): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=2, bias=True)
      (1): LogSoftmax(dim=1)
    )
  )
)
CUDA is available! Training on GPU...
Epoch: 1/30
Epoch: 001, Training: Loss: 2.4117, Accuracy: 79.2849%, 
		Validation: Loss: 2.4117, Accuracy: 81.0225%, Time: 5400.0131s
Best Accuracy for validation : 0.8102 at epoch 001
Epoch: 2/30
Epoch: 002, Training: Loss: 0.4453, Accuracy: 80.2600%, 
		Validation: Loss: 0.4453, Accuracy: 81.0225%, Time: 6927.9905s
Best Accuracy for validation : 0.8102 at epoch 001
Epoch: 3/30
Epoch: 003, Training: Loss: 0.4330, Accuracy: 80.1083%, 
		Validation: Loss: 0.4330, Accuracy: 81.1092%, Time: 6855.7581s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 4/30
Epoch: 004, Training: Loss: 0.4390, Accuracy: 80.3684%, 
		Validation: Loss: 0.4390, Accuracy: 80.8492%, Time: 6899.5597s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 5/30
Epoch: 005, Training: Loss: 0.6325, Accuracy: 80.3684%, 
		Validation: Loss: 0.6325, Accuracy: 81.0225%, Time: 6931.3609s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 6/30
Epoch: 006, Training: Loss: 0.4445, Accuracy: 80.1083%, 
		Validation: Loss: 0.4445, Accuracy: 81.0225%, Time: 6787.5841s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 7/30
Epoch: 007, Training: Loss: 2.4123, Accuracy: 80.3900%, 
		Validation: Loss: 2.4123, Accuracy: 81.0225%, Time: 5278.2348s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 8/30
Epoch: 008, Training: Loss: 0.5416, Accuracy: 80.2817%, 
		Validation: Loss: 0.5416, Accuracy: 79.9827%, Time: 5577.3714s
Best Accuracy for validation : 0.8111 at epoch 003
Epoch: 9/30
Epoch: 009, Training: Loss: 0.4218, Accuracy: 80.3684%, 
		Validation: Loss: 0.4218, Accuracy: 81.3692%, Time: 6987.0159s
Best Accuracy for validation : 0.8137 at epoch 009
Epoch: 10/30
Epoch: 010, Training: Loss: 0.4317, Accuracy: 80.5634%, 
		Validation: Loss: 0.4317, Accuracy: 78.7695%, Time: 6745.9005s
Best Accuracy for validation : 0.8137 at epoch 009
Epoch: 11/30
Epoch: 011, Training: Loss: 0.4128, Accuracy: 80.7367%, 
		Validation: Loss: 0.4128, Accuracy: 82.3224%, Time: 6894.3709s
Best Accuracy for validation : 0.8232 at epoch 011
Epoch: 12/30
Epoch: 012, Training: Loss: 0.4161, Accuracy: 80.9534%, 
		Validation: Loss: 0.4161, Accuracy: 81.1092%, Time: 6992.9630s
Best Accuracy for validation : 0.8232 at epoch 011
Epoch: 13/30
Epoch: 013, Training: Loss: 0.5158, Accuracy: 80.8451%, 
		Validation: Loss: 0.5158, Accuracy: 78.2496%, Time: 6850.5677s
Best Accuracy for validation : 0.8232 at epoch 011
Epoch: 14/30
Epoch: 014, Training: Loss: 0.4869, Accuracy: 80.6717%, 
		Validation: Loss: 0.4869, Accuracy: 76.8631%, Time: 6739.8079s
Best Accuracy for validation : 0.8232 at epoch 011
Epoch: 15/30
Epoch: 015, Training: Loss: 0.4049, Accuracy: 80.9967%, 
		Validation: Loss: 0.4049, Accuracy: 82.2357%, Time: 5976.3756s
Best Accuracy for validation : 0.8232 at epoch 011
Epoch: 16/30
Epoch: 016, Training: Loss: 0.3897, Accuracy: 80.9967%, 
		Validation: Loss: 0.3897, Accuracy: 82.5823%, Time: 5531.1930s
Best Accuracy for validation : 0.8258 at epoch 016
Epoch: 17/30
Epoch: 017, Training: Loss: 0.3906, Accuracy: 81.6468%, 
		Validation: Loss: 0.3906, Accuracy: 81.1958%, Time: 5512.5153s
Best Accuracy for validation : 0.8258 at epoch 016
Epoch: 18/30
Epoch: 018, Training: Loss: 0.3771, Accuracy: 81.0834%, 
		Validation: Loss: 0.3771, Accuracy: 82.5823%, Time: 5441.0089s
Best Accuracy for validation : 0.8258 at epoch 016
Epoch: 19/30
Epoch: 019, Training: Loss: 0.5944, Accuracy: 82.0152%, 
		Validation: Loss: 0.5944, Accuracy: 75.1300%, Time: 5444.0229s
Best Accuracy for validation : 0.8258 at epoch 016
Epoch: 20/30
Epoch: 020, Training: Loss: 0.3686, Accuracy: 82.1018%, 
		Validation: Loss: 0.3686, Accuracy: 83.2756%, Time: 5441.4389s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 21/30
Epoch: 021, Training: Loss: 0.3971, Accuracy: 81.5601%, 
		Validation: Loss: 0.3971, Accuracy: 80.6759%, Time: 5434.5665s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 22/30
Epoch: 022, Training: Loss: 0.4168, Accuracy: 82.1668%, 
		Validation: Loss: 0.4168, Accuracy: 81.2825%, Time: 5471.5980s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 23/30
Epoch: 023, Training: Loss: 0.3891, Accuracy: 81.5385%, 
		Validation: Loss: 0.3891, Accuracy: 82.7556%, Time: 5718.1649s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 24/30
Epoch: 024, Training: Loss: 0.3916, Accuracy: 81.7118%, 
		Validation: Loss: 0.3916, Accuracy: 82.4090%, Time: 5544.9729s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 25/30
Epoch: 025, Training: Loss: 0.3980, Accuracy: 81.7985%, 
		Validation: Loss: 0.3980, Accuracy: 81.3692%, Time: 5504.1116s
Best Accuracy for validation : 0.8328 at epoch 020
Epoch: 26/30
Epoch: 026, Training: Loss: 0.3761, Accuracy: 82.3619%, 
		Validation: Loss: 0.3761, Accuracy: 83.4489%, Time: 5575.4594s
Best Accuracy for validation : 0.8345 at epoch 026
Epoch: 27/30
Epoch: 027, Training: Loss: 0.3666, Accuracy: 82.6869%, 
		Validation: Loss: 0.3666, Accuracy: 83.6222%, Time: 5596.8865s
Best Accuracy for validation : 0.8362 at epoch 027
Epoch: 28/30
Epoch: 028, Training: Loss: 0.3757, Accuracy: 82.7519%, 
		Validation: Loss: 0.3757, Accuracy: 82.9289%, Time: 5575.1347s
Best Accuracy for validation : 0.8362 at epoch 027
Epoch: 29/30
Epoch: 029, Training: Loss: 0.6340, Accuracy: 82.1885%, 
		Validation: Loss: 0.6340, Accuracy: 71.4038%, Time: 5564.0998s
Best Accuracy for validation : 0.8362 at epoch 027
Epoch: 30/30
Epoch: 030, Training: Loss: 0.3779, Accuracy: 82.5135%, 
		Validation: Loss: 0.3779, Accuracy: 82.0624%, Time: 5584.7838s
Best Accuracy for validation : 0.8362 at epoch 027
